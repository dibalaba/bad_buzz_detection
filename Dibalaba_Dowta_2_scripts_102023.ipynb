{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG8GkEubTXXG",
        "outputId": "b71711c7-a048-4f50-c6ba-30a3b6591a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.8.0-py3-none-any.whl (19.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow)\n",
            "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.3.post1)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.2)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.8.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<7,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.23.5)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.3)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.22)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: pyarrow<14,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (9.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.5)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: psutil<6 in /usr/local/lib/python3.10/dist-packages (from mlflow) (5.9.5)\n",
            "Collecting gunicorn<22 (from mlflow)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.2)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.5.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.0.7)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow) (1.6.4)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, querystring-parser, Mako, gunicorn, gitdb, docker, databricks-cli, alembic, gitpython, mlflow\n",
            "Successfully installed Mako-1.2.4 alembic-1.12.1 databricks-cli-0.18.0 docker-6.1.3 gitdb-4.0.11 gitpython-3.1.40 gunicorn-21.2.0 mlflow-2.8.0 querystring-parser-1.2.4 smmap-5.0.1\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.0.0.tar.gz (718 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.7/718.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-7.0.0-py3-none-any.whl size=21129 sha256=4c3556ce969fdcdec2d9e8775c4f86f55667619e24d8f752c868358988f2b83c\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/29/7b/f64332aa7e5e88fbd56d4002185ae22dcdc83b35b3d1c2cbf5\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.0.0\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.5.0)\n",
            "Installing collected packages: h11, uvicorn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 uvicorn-0.23.2\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets --upgrade\n",
        "!pip install mlflow\n",
        "!pip install pyngrok\n",
        "!pip install pyyaml\n",
        "!pip install keras\n",
        "!pip install uvicorn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZUjdQoDmN8o0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxEAKNb-TYfQ",
        "outputId": "c614c300-7759-4786-9be5-116a37c196ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.7.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (1.10.13)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.8.0 (from fastapi)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.1.3)\n",
            "Installing collected packages: typing-extensions, starlette, fastapi\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "orbax-checkpoint 0.4.1 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fastapi-0.104.1 starlette-0.27.0 typing-extensions-4.8.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.8/529.8 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.8/529.8 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.1/439.1 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.1/439.1 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "flask 2.2.5 requires click>=8.0, but you have click 7.1.2 which is incompatible.\n",
            "dask 2023.8.1 requires click>=8.0, but you have click 7.1.2 which is incompatible.\n",
            "distributed 2023.8.1 requires click>=8.0, but you have click 7.1.2 which is incompatible.\n",
            "fiona 1.9.5 requires click~=8.0, but you have click 7.1.2 which is incompatible.\n",
            "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.4.5 which is incompatible.\n",
            "orbax-checkpoint 0.4.1 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\n",
            "pip-tools 6.13.0 requires click>=8, but you have click 7.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: google-colab in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: google-auth==2.17.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.17.3)\n",
            "Requirement already satisfied: ipykernel==5.5.6 in /usr/local/lib/python3.10/dist-packages (from google-colab) (5.5.6)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (7.34.0)\n",
            "Collecting notebook==6.5.5 (from google-colab)\n",
            "  Downloading notebook-6.5.5-py3-none-any.whl (529 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.8/529.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (1.5.3)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.10/dist-packages (from google-colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.31.0)\n",
            "Requirement already satisfied: tornado==6.3.2 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.3.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (4.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (6.1.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (4.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (3.1.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (5.4.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (6.5.4)\n",
            "Collecting nest-asyncio>=1.5 (from notebook==6.5.5->google-colab)\n",
            "  Downloading nest_asyncio-1.5.8-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (0.17.1)\n",
            "Collecting nbclassic>=0.4.7 (from notebook==6.5.5->google-colab)\n",
            "  Downloading nbclassic-1.0.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (1.23.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker==1.5.2->google-colab) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (2023.7.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook==6.5.5->google-colab) (3.11.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->google-colab) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (23.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->google-colab) (2.18.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->google-colab) (4.19.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.8)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.17.3->google-colab) (0.5.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook==6.5.5->google-colab) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.10.6)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.6.4)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.5->google-colab) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook==6.5.5->google-colab) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (2.21)\n",
            "Installing collected packages: nest-asyncio, nbclassic, notebook\n",
            "  Attempting uninstall: nest-asyncio\n",
            "    Found existing installation: nest-asyncio 1.4.3\n",
            "    Uninstalling nest-asyncio-1.4.3:\n",
            "      Successfully uninstalled nest-asyncio-1.4.3\n",
            "  Attempting uninstall: nbclassic\n",
            "    Found existing installation: nbclassic 0.3.7\n",
            "    Uninstalling nbclassic-0.3.7:\n",
            "      Successfully uninstalled nbclassic-0.3.7\n",
            "  Attempting uninstall: notebook\n",
            "    Found existing installation: notebook 6.4.5\n",
            "    Uninstalling notebook-6.4.5:\n",
            "      Successfully uninstalled notebook-6.4.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "colabcode 0.3.0 requires nest-asyncio==1.4.3, but you have nest-asyncio 1.5.8 which is incompatible.\n",
            "jupyterlab 3.0.7 requires nbclassic~=0.2, but you have nbclassic 1.0.0 which is incompatible.\n",
            "orbax-checkpoint 0.4.1 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nbclassic-1.0.0 nest-asyncio-1.5.8 notebook-6.5.5\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "!pip install fastapi\n",
        "!pip install -q colabcode\n",
        "!pip install google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blrLK48BVjjv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y16BeeGmIRJZ",
        "outputId": "e0d22b45-e280-457f-f945-18a03a30c6dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text==2.13.*\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text==2.13.*) (0.15.0)\n",
            "Collecting tensorflow<2.14,>=2.13.0 (from tensorflow-text==2.13.*)\n",
            "  Downloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.7/479.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.9.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.17.3)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.2.2)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, keras, google-auth-oauthlib, tensorboard, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.8.0\n",
            "    Uninstalling typing_extensions-4.8.0:\n",
            "      Successfully uninstalled typing_extensions-4.8.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 0.4.6\n",
            "    Uninstalling google-auth-oauthlib-0.4.6:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.0\n",
            "    Uninstalling tensorboard-2.12.0:\n",
            "      Successfully uninstalled tensorboard-2.12.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "fastapi 0.104.1 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "orbax-checkpoint 0.4.1 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-1.0.0 keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-text-2.13.0 typing-extensions-4.5.0\n",
            "Collecting tf-models-official==2.13.*\n",
            "  Downloading tf_models_official-2.13.2-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (3.0.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (9.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official==2.13.*)\n",
            "  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.5.16)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.23.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (4.8.1.78)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (6.0.1)\n",
            "Collecting sacrebleu (from tf-models-official==2.13.*)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.11.3)\n",
            "Collecting sentencepiece (from tf-models-official==2.13.*)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official==2.13.*)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (4.9.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (0.15.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.13.*)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-text~=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: tensorflow~=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.13.1)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (4.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (6.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official==2.13.*) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.34.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.13.*) (0.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.*) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.*) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.*) (4.9)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official==2.13.*)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official==2.13.*)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (4.9.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.13.*) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (7.1.2)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.5.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.41.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (6.1.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (3.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (1.61.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (5.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.13.*) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.13.*) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.0.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.13.*) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.13.*) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.2.2)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=643e7b703e7991646b26e707b732829c483e18c984d864eadd355fd3cb51d5ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: sentencepiece, tensorflow-model-optimization, portalocker, immutabledict, colorama, sacrebleu, seqeval, tf-models-official\n",
            "Successfully installed colorama-0.4.6 immutabledict-3.0.0 portalocker-2.8.2 sacrebleu-2.3.1 sentencepiece-0.1.99 seqeval-1.2.2 tensorflow-model-optimization-0.7.5 tf-models-official-2.13.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \"tensorflow-text==2.13.*\"\n",
        "!pip install \"tf-models-official==2.13.*\"\n",
        "!apt-get install git-lfs\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mskEe4uUVjll"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sPdU2EDVjo9",
        "outputId": "721ccefe-e16e-4315-b589-3c850a42f47a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.6 dill-0.3.7 multiprocess-0.70.15\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EyqIJiSVrnY",
        "outputId": "ec30b676-fe7f-4804-974c-31dbd4b46a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import opendatasets as od\n",
        "import re\n",
        "import nltk\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import mlflow\n",
        "import pyngrok\n",
        "import tensorflow as tf\n",
        "## Visualization ##\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "## ML Modelling ##\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import (accuracy_score,\n",
        "                             precision_score,\n",
        "                             recall_score,\n",
        "                             f1_score)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "print(tf.__version__)\n",
        "# helps in text preprocessing\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# helps in model building\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import seaborn as sns\n",
        "# split data into train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "from pyngrok import ngrok\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from transformers import InputExample, InputFeatures\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Dropout, Embedding\n",
        "from keras.optimizers import Adam\n",
        "tf.keras.optimizers.legacy.Adam\n",
        "from transformers import TFBertModel\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import load_metric\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "# A dependency of the preprocessing for BERT inputs\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QIWl8PSPVrqx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import configs for github from google drive"
      ],
      "metadata": {
        "id": "16ZXmj5W8F5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rh2jEWSVVruJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lgcXvlEqVryj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71ac9a9b-efd8-4977-d832-6082567db6ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Cloning into 'bad_buzz_detection'...\n",
            "remote: Enumerating objects: 158, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 158 (delta 51), reused 121 (delta 39), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (158/158), 239.00 KiB | 3.10 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "/content/bad_buzz_detection\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive_path = \"/content/gdrive\"\n",
        "drive.mount(drive_path,force_remount=True)\n",
        "\n",
        "# Load the general config\n",
        "config_path = os.path.join(drive_path, \"MyDrive\", \"general_config.yml\")\n",
        "with open(config_path, 'r') as yml:\n",
        "  config = yaml.safe_load(yml)\n",
        "\n",
        "config_github = config[\"github\"]\n",
        "config_ngrok = config[\"ngrok\"]\n",
        "\n",
        "# Set git configs\n",
        "!git config --global user.email {config_github[\"email\"]}\n",
        "!git config --global user.name {config_github[\"username\"]}\n",
        "\n",
        "# Clone the repository\n",
        "repository_name = \"bad_buzz_detection\"\n",
        "git_repository = f\"https://github.com/dibalaba/\" + repository_name + \".git\"\n",
        "repository_path = \"/content/\" + repository_name\n",
        "!git clone {git_repository}\n",
        "\n",
        "# Change the current directory to the cloned directory\n",
        "%cd {repository_name}\n",
        "\n",
        "# Checkout branch\n",
        "branch_name = \"main\"\n",
        "!git checkout {branch_name}\n",
        "\n",
        "# Pull\n",
        "!git pull origin"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fAY-lOG2aLyF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WBioZ2bVaL1b"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA COLLECTION"
      ],
      "metadata": {
        "id": "dTrbnQPt79RD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QTMSgQLN76Ui"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbRFodfaWKTJ",
        "outputId": "1fc7bf62-6591-47b0-81b3-7fe5c9e9ad1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: dowtadibalaba\n",
            "Your Kaggle Key: ··········\n",
            "Downloading sentiment-train.zip to ./sentiment-train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80.9M/80.9M [00:00<00:00, 105MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dataset_url = 'https://www.kaggle.com/datasets/dowtadibalaba/sentiment-train'\n",
        "od.download(dataset_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ihRL8Zu0WKVq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RLGvM0dw71MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data collected into dataframe"
      ],
      "metadata": {
        "id": "PJF7DMeG71ze"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "siI_JtOgWKX9",
        "outputId": "149bca53-e36d-43c0-cc1a-7305b5dd9f72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   target          id                          date      flag  \\\n",
              "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                               text  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-164bb683-74eb-4526-b7be-57dcd6171aee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-164bb683-74eb-4526-b7be-57dcd6171aee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-164bb683-74eb-4526-b7be-57dcd6171aee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-164bb683-74eb-4526-b7be-57dcd6171aee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b88428e-ac7f-4902-94e0-ad7fd43436d4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b88428e-ac7f-4902-94e0-ad7fd43436d4')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b88428e-ac7f-4902-94e0-ad7fd43436d4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\n",
        "df=pd.read_csv('./sentiment-train/training_sentiment.csv',encoding=\"ISO-8859-1\",header=None,names=['target','id','date','flag','user','text'])\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ0CGATjWKal"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uidt8imOWYz7"
      },
      "outputs": [],
      "source": [
        "df_pos=df.loc[df['target']== 4]\n",
        "df_neg=df.loc[df['target']== 0]\n",
        "df_pos['target'].replace(4, 1, inplace=True)\n",
        "df=pd.concat([df_neg.sample(8000),df_pos.sample(8000)])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kln8U9xIz38e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive_path = \"/content/gdrive\"\n",
        "drive.mount(drive_path,force_remount=True)\n",
        "\n",
        "# Load the general config\n",
        "contractions_path = os.path.join(drive_path, \"MyDrive\", \"contractions.json\")\n",
        "with open(contractions_path, 'r') as yml:\n",
        "  contractions = yaml.safe_load(yml)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4POAzVtlz4IU",
        "outputId": "51201c9e-6c73-4468-e706-787a2137c678"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gduvhkMIz4Vr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some utility functions to help"
      ],
      "metadata": {
        "id": "vS3-YJt58RIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ghXAenFN8RLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_-p7uIdL8SCE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "t-SWcCYhWY2P"
      },
      "outputs": [],
      "source": [
        "def text_preprocessing(text):\n",
        "    import json\n",
        "    #contractions_path = os.path.join(drive_path, \"MyDrive\", \"contractions.json\")\n",
        "    #with open(contractions_path, 'r') as yml:\n",
        "     #contractions = yaml.safe_load(yml)\n",
        "\n",
        "    #with open('/content/contractions.json', 'r') as f:\n",
        "    # contractions = json.loads(f.read())\n",
        "    # Convert words to lower case\n",
        "    text = text.lower()\n",
        "\n",
        "    # Expand contractions\n",
        "    if True:\n",
        "        text = text.split()\n",
        "        new_text = []\n",
        "        for word in text:\n",
        "            if word in contractions:\n",
        "                new_text.append(contractions[word])\n",
        "            else:\n",
        "                new_text.append(word)\n",
        "        text = \" \".join(new_text)\n",
        "\n",
        "    # Format words and remove unwanted characters\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\<a href', ' ', text)\n",
        "    text = re.sub(r'&amp;', '', text)\n",
        "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
        "    text = re.sub(r'<br />', ' ', text)\n",
        "    text = re.sub(r'\\'', ' ', text)\n",
        "\n",
        "    # Tokenize each word\n",
        "    #text = nltk.WordPunctTokenizer().tokenize(text)\n",
        "\n",
        "    # Lemmatize each word\n",
        "    #text = [nltk.stem.WordNetLemmatizer().lemmatize(token, pos='v') for token in text if len(token)>1]\n",
        "    #text= (x.lower() for x in text)\n",
        "\n",
        "    return str(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YaQpx1ZXw6TB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def c_report(y_true, y_pred):\n",
        "   print(\"Classification Report\")\n",
        "   print(classification_report(y_true, y_pred))\n",
        "   acc_sc = accuracy_score(y_true, y_pred)\n",
        "   print(\"Accuracy : \"+ str(acc_sc))\n",
        "   return acc_sc\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "   mtx = confusion_matrix(y_true, y_pred)\n",
        "   sns.heatmap(mtx, annot=True, fmt='d', linewidths=.5,\n",
        "               cmap=\"Blues\", cbar=False)\n",
        "   plt.ylabel('True label')\n",
        "   plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "J4BNjj98w6bf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vogsxBL6WY4o",
        "outputId": "4e77e315-9179-46a0-8474-d4b7c1ba077f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        target                                               text\n",
              "770378       0  TRYING to understand how this thing works and ...\n",
              "84748        0     I am back! After realizing that my comp sucks \n",
              "209380       0  @ArchAngelica17 I'm sorry  Want a virtual Arch...\n",
              "19247        0  UPDATE MONTAAAAAAAGE. Everything I hoped for, ...\n",
              "600331       0  Off to work then Calirayaaa. I'm excited but I..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55fdfc2c-b9e7-446d-af15-882863f406e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>770378</th>\n",
              "      <td>0</td>\n",
              "      <td>TRYING to understand how this thing works and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84748</th>\n",
              "      <td>0</td>\n",
              "      <td>I am back! After realizing that my comp sucks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209380</th>\n",
              "      <td>0</td>\n",
              "      <td>@ArchAngelica17 I'm sorry  Want a virtual Arch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19247</th>\n",
              "      <td>0</td>\n",
              "      <td>UPDATE MONTAAAAAAAGE. Everything I hoped for, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600331</th>\n",
              "      <td>0</td>\n",
              "      <td>Off to work then Calirayaaa. I'm excited but I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55fdfc2c-b9e7-446d-af15-882863f406e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-55fdfc2c-b9e7-446d-af15-882863f406e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-55fdfc2c-b9e7-446d-af15-882863f406e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d7386cc-5049-4201-b68b-147fe7b6265e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d7386cc-5049-4201-b68b-147fe7b6265e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d7386cc-5049-4201-b68b-147fe7b6265e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df_copy=df\n",
        "data=df.drop(columns=[ 'id', 'date', 'flag', 'user'])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m5ex2HTO6zLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLops logic implementation"
      ],
      "metadata": {
        "id": "i5j4WU3s8dAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classical models"
      ],
      "metadata": {
        "id": "Ve7VC4eQAPyE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iCvwSO7ZWY8N"
      },
      "outputs": [],
      "source": [
        "ratio_train = 0.8\n",
        "ratio_val = 0.1\n",
        "ratio_test = 0.1\n",
        "\n",
        "X_remaining, X_test, y_remaining, y_test = train_test_split(data['text'],data['target'], stratify=data['target'],test_size=ratio_test)\n",
        "ratio_remaining = 1 - ratio_test\n",
        "ratio_val_adjusted = ratio_val / ratio_remaining\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "                X_remaining, y_remaining, test_size=ratio_val_adjusted)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9LDctZuxst6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naïve Binomial**"
      ],
      "metadata": {
        "id": "P6jPIQSJAoUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def simple_model(experiment_name: str, run_name: str):\n",
        "\n",
        "\n",
        "\n",
        "        # Fix and log seed value\n",
        "        seed=123\n",
        "        np.random.seed(seed)\n",
        "        #mlflow.log_param(\"numpy seed\", seed)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Defines ratios, w.r.t. whole dataset.\n",
        "        ratio_train = 0.8\n",
        "        ratio_val = 0.1\n",
        "        ratio_test = 0.1\n",
        "        #mlflow.log_param(\"train size\", ratio_train)\n",
        "        #mlflow.log_param(\"test size\", ratio_test)\n",
        "        #mlflow.log_param(\"validation size\", ratio_val)\n",
        "\n",
        "        # Produces test split.\n",
        "        x_remaining, x_test, y_remaining, y_test = train_test_split(\n",
        "            df.text, df.target, test_size=ratio_test)\n",
        "\n",
        "        # Adjusts val ratio, w.r.t. remaining dataset.\n",
        "        ratio_remaining = 1 - ratio_test\n",
        "        ratio_val_adjusted = ratio_val / ratio_remaining\n",
        "        x_train, x_val, y_train, y_val = train_test_split(\n",
        "                x_remaining, y_remaining, test_size=ratio_val_adjusted)\n",
        "        mlflow.end_run()\n",
        "        # Produces train and val splits.\n",
        "        mlflow.set_experiment(experiment_name)\n",
        "        with mlflow.start_run(run_name=run_name):\n",
        "            #mlflow.log_param(\"numpy seed\", seed)\n",
        "            #mlflow.log_param(\"train size\", ratio_train)\n",
        "            #mlflow.log_param(\"test size\", ratio_test)\n",
        "            #mlflow.log_param(\"validation size\", ratio_val)\n",
        "\n",
        "        # Log automatically\n",
        "            mlflow.sklearn.autolog()\n",
        "\n",
        "            vectorizer = TfidfVectorizer()\n",
        "            x_train_vectorized = vectorizer.fit_transform(x_train)\n",
        "            x_test_vectorized = vectorizer.transform(x_test)\n",
        "            x_val_vectorized  = vectorizer.transform(x_val)\n",
        "\n",
        "            naive_bayes = MultinomialNB()\n",
        "            naive_bayes.fit(x_train_vectorized, y_train)\n",
        "            mlflow.log_param(\"validation size\", ratio_val)\n",
        "            scores = cross_val_score(naive_bayes,x_val_vectorized,y_val, cv = 10, scoring='accuracy')\n",
        "            print(scores)\n",
        "            #test_predicted = np.argmax(analyser.predict(x_test_vectorized), axis=0)\n",
        "            test_predicted = naive_bayes.predict(x_test_vectorized)\n",
        "            accuracy=accuracy_score(y_test, test_predicted, normalize=True)\n",
        "            f1_Score= f1_score(y_test, test_predicted)\n",
        "            #accuracy = sum(test_predicted == y_test) / len(test_predicted)\n",
        "            mlflow.log_metric(\"accuracy\", accuracy)\n",
        "            mlflow.log_metric(\"f1_Score\", f1_Score)\n",
        "\n",
        "            #print(f\"accuracy is {accuracy}.\")"
      ],
      "metadata": {
        "id": "V2XoD1mdxswb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F1vzX3l0xszJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "7nSsbNw6A4v2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regLog_model(experiment_name: str, run_name: str):\n",
        "\n",
        "\n",
        "\n",
        "        # Fix and log seed value\n",
        "        seed=123\n",
        "        np.random.seed(seed)\n",
        "        mlflow.log_param(\"numpy seed\", seed)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Defines ratios, w.r.t. whole dataset.\n",
        "        ratio_train = 0.8\n",
        "        ratio_val = 0.1\n",
        "        ratio_test = 0.1\n",
        "        #mlflow.log_param(\"train size\", ratio_train)\n",
        "        #mlflow.log_param(\"test size\", ratio_test)\n",
        "        #mlflow.log_param(\"validation size\", ratio_val)\n",
        "\n",
        "        # Produces test split.\n",
        "        x_remaining, x_test, y_remaining, y_test = train_test_split(\n",
        "            df.text, df.target, test_size=ratio_test)\n",
        "\n",
        "        # Adjusts val ratio, w.r.t. remaining dataset.\n",
        "        ratio_remaining = 1 - ratio_test\n",
        "        ratio_val_adjusted = ratio_val / ratio_remaining\n",
        "        x_train, x_val, y_train, y_val = train_test_split(\n",
        "                x_remaining, y_remaining, test_size=ratio_val_adjusted)\n",
        "\n",
        "\n",
        "        mlflow.end_run()\n",
        "        # Produces train and val splits.\n",
        "        mlflow.set_experiment(experiment_name)\n",
        "        with mlflow.start_run(run_name=run_name):\n",
        "        # Log automatically\n",
        "            mlflow.sklearn.autolog()\n",
        "            vectorizer = TfidfVectorizer()\n",
        "            x_train_vectorized = vectorizer.fit_transform(x_train)\n",
        "            x_test_vectorized = vectorizer.transform(x_test)\n",
        "            x_val_vectorized  = vectorizer.transform(x_val)\n",
        "\n",
        "\n",
        "            analyser=LogisticRegressionCV(cv=5,\n",
        "                      scoring='accuracy',\n",
        "                      random_state=0,\n",
        "                      n_jobs=-1,\n",
        "                      verbose=3,\n",
        "                      max_iter=300)\n",
        "            analyser.fit(x_train_vectorized, y_train)\n",
        "\n",
        "            scores = cross_val_score(analyser,x_val_vectorized,y_val, cv = 10, scoring='accuracy')\n",
        "            mlflow.log_param(\"score\", scores)\n",
        "            print(scores)\n",
        "            #test_predicted = np.argmax(analyser.predict(x_test_vectorized), axis=0)\n",
        "            test_predicted = analyser.predict(x_test_vectorized)\n",
        "            accuracy=accuracy_score(y_test, test_predicted, normalize=True)\n",
        "            f1_Score= f1_score(y_test, test_predicted)\n",
        "            mlflow.log_metric(\"accuracy\", accuracy)\n",
        "            mlflow.log_metric(\"f1_Score\", f1_Score)"
      ],
      "metadata": {
        "id": "uCWQgZtdxs1y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqQkWhoMxs4b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rnn model**"
      ],
      "metadata": {
        "id": "ve6jL2J5BI0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rnn_model(experiment_name: str, run_name: str):\n",
        "    X = data['text'].values\n",
        "    y = data['target'].values\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "    mlflow.end_run()\n",
        "        # Produces train and val splits.\n",
        "    mlflow.set_experiment(experiment_name)\n",
        "\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "      mlflow.sklearn.autolog()\n",
        "      t = Tokenizer()\n",
        "      t.fit_on_texts(X_train)\n",
        "\n",
        "      encoded_train = t.texts_to_sequences(X_train)\n",
        "      encoded_test = t.texts_to_sequences(X_test)\n",
        "      print(encoded_train[0:2])\n",
        "\n",
        "      max_length = 8\n",
        "      padded_train = pad_sequences(encoded_train, maxlen=max_length, padding='post')\n",
        "      padded_test = pad_sequences(encoded_test, maxlen=max_length, padding='post')\n",
        "      print(padded_train)\n",
        "\n",
        "      vocab_size = len(t.word_index) + 1\n",
        "\n",
        "      # define the model\n",
        "      model = Sequential()\n",
        "      model.add(Embedding(vocab_size, 24, input_length=max_length))\n",
        "      model.add(SimpleRNN(24, return_sequences=False))\n",
        "      model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "      # compile the model\n",
        "      model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      # summarize the model\n",
        "      print(model.summary())\n",
        "\n",
        "      early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "      # fit the model\n",
        "      model.fit(x=padded_train,\n",
        "         y=y_train,\n",
        "         epochs=100,\n",
        "         validation_data=(padded_test, y_test), verbose=1,\n",
        "         #callbacks=[early_stop]\n",
        "         )\n",
        "\n",
        "      preds = (model.predict(padded_test) > 0.7).astype(\"int32\")\n",
        "      c_report(y_test, preds)\n",
        "      plot_confusion_matrix(y_test, preds)\n",
        "      accuracy=accuracy_score(y_test, preds, normalize=True)\n",
        "      f1_Score= f1_score(y_test, preds)\n",
        "      mlflow.log_metric(\"accuracy\", accuracy)\n",
        "      mlflow.log_metric(\"f1_Score\", f1_Score)\n",
        "\n",
        "\n",
        "      return model"
      ],
      "metadata": {
        "id": "HCu2mGzSxs67"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_o06q5Exs_r"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model('first model','basic run')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB_8DfQNx_pW",
        "outputId": "1d91c147-b2b2-4ae9-96b4-43f64d5596f1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/10/31 08:59:16 INFO mlflow.tracking.fluent: Experiment with name 'first model' does not exist. Creating a new experiment.\n",
            "2023/10/31 08:59:17 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "2023/10/31 08:59:21 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
            "2023/10/31 08:59:21 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "2023/10/31 08:59:24 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "2023/10/31 08:59:26 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "2023/10/31 08:59:29 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "2023/10/31 08:59:32 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "2023/10/31 08:59:34 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "2023/10/31 08:59:37 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "2023/10/31 08:59:40 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "2023/10/31 08:59:42 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "2023/10/31 08:59:45 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6875  0.7125  0.6625  0.63125 0.6625  0.70625 0.725   0.68125 0.66875\n",
            " 0.625  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regLog_model('run logistic regression','log reg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4NDLTlxx_qL",
        "outputId": "7094227e-8235-43b9-a484-0ef29209242c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/10/31 09:03:21 INFO mlflow.tracking.fluent: Experiment with name 'run logistic regression' does not exist. Creating a new experiment.\n",
            "2023/10/31 09:03:22 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    8.1s remaining:   12.2s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.4s finished\n",
            "2023/10/31 09:03:35 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.2s remaining:    4.8s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.5s finished\n",
            "2023/10/31 09:03:41 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.2s remaining:    4.8s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.6s finished\n",
            "2023/10/31 09:03:48 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.0s remaining:    4.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.3s finished\n",
            "2023/10/31 09:03:54 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.1s remaining:    4.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.5s finished\n",
            "2023/10/31 09:04:01 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.2s remaining:    4.9s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.6s finished\n",
            "2023/10/31 09:04:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.2s remaining:    4.8s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.6s finished\n",
            "2023/10/31 09:04:14 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.3s remaining:    5.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s finished\n",
            "2023/10/31 09:04:21 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.2s remaining:    3.3s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.8s finished\n",
            "2023/10/31 09:04:27 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.5s remaining:    3.7s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.1s finished\n",
            "2023/10/31 09:04:33 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.0s remaining:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.73125 0.73125 0.7     0.68125 0.66875 0.71875 0.7625  0.65625 0.6625\n",
            " 0.625  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=rnn_model('rnn_model','rnn_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2pkKGxvvx_q_",
        "outputId": "7d595bbf-4cb2-4142-b2a3-bb4708cfe3b1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/10/31 09:17:45 INFO mlflow.tracking.fluent: Experiment with name 'rnn_model' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[226, 72, 32, 5, 1660, 49, 260, 72, 370, 6821, 731, 90, 71, 563, 1845, 18, 466, 5, 4438], [6822, 189, 120, 339, 4, 859, 12, 860]]\n",
            "[[   90    71   563 ...   466     5  4438]\n",
            " [ 6822   189   120 ...   859    12   860]\n",
            " [    1    78    66 ...    23     4   321]\n",
            " ...\n",
            " [    1    64     1 ...  1184    61 22810]\n",
            " [  536     4   243 ...    90   433     9]\n",
            " [    1    16    41 ...     8     4  1651]]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 8, 24)             547512    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 24)                1176      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 548713 (2.09 MB)\n",
            "Trainable params: 548713 (2.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "400/400 [==============================] - 3s 4ms/step - loss: 0.6228 - accuracy: 0.6415 - val_loss: 0.5685 - val_accuracy: 0.7006\n",
            "Epoch 2/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.4922 - accuracy: 0.7668 - val_loss: 0.5658 - val_accuracy: 0.7128\n",
            "Epoch 3/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.4108 - accuracy: 0.8145 - val_loss: 0.6283 - val_accuracy: 0.6966\n",
            "Epoch 4/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.3344 - accuracy: 0.8588 - val_loss: 0.6839 - val_accuracy: 0.6841\n",
            "Epoch 5/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.2670 - accuracy: 0.8932 - val_loss: 0.7192 - val_accuracy: 0.6869\n",
            "Epoch 6/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.2127 - accuracy: 0.9166 - val_loss: 0.7867 - val_accuracy: 0.6803\n",
            "Epoch 7/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.1643 - accuracy: 0.9384 - val_loss: 0.9043 - val_accuracy: 0.6628\n",
            "Epoch 8/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.1302 - accuracy: 0.9523 - val_loss: 0.9437 - val_accuracy: 0.6653\n",
            "Epoch 9/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.1047 - accuracy: 0.9608 - val_loss: 1.0279 - val_accuracy: 0.6541\n",
            "Epoch 10/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0836 - accuracy: 0.9697 - val_loss: 1.1105 - val_accuracy: 0.6550\n",
            "Epoch 11/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0683 - accuracy: 0.9759 - val_loss: 1.1609 - val_accuracy: 0.6522\n",
            "Epoch 12/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0567 - accuracy: 0.9814 - val_loss: 1.2547 - val_accuracy: 0.6469\n",
            "Epoch 13/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0469 - accuracy: 0.9826 - val_loss: 1.2908 - val_accuracy: 0.6419\n",
            "Epoch 14/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9868 - val_loss: 1.3298 - val_accuracy: 0.6366\n",
            "Epoch 15/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9893 - val_loss: 1.4844 - val_accuracy: 0.6172\n",
            "Epoch 16/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0263 - accuracy: 0.9914 - val_loss: 1.5296 - val_accuracy: 0.6406\n",
            "Epoch 17/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 1.6844 - val_accuracy: 0.6372\n",
            "Epoch 18/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 1.7998 - val_accuracy: 0.6284\n",
            "Epoch 19/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 1.7892 - val_accuracy: 0.6381\n",
            "Epoch 20/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 1.9473 - val_accuracy: 0.6316\n",
            "Epoch 21/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 2.0470 - val_accuracy: 0.6356\n",
            "Epoch 22/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 2.1606 - val_accuracy: 0.6284\n",
            "Epoch 23/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 2.2416 - val_accuracy: 0.6341\n",
            "Epoch 24/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 2.2995 - val_accuracy: 0.6297\n",
            "Epoch 25/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 2.5205 - val_accuracy: 0.6244\n",
            "Epoch 26/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 2.5434 - val_accuracy: 0.6172\n",
            "Epoch 27/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 2.6445 - val_accuracy: 0.6259\n",
            "Epoch 28/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 2.8365 - val_accuracy: 0.6141\n",
            "Epoch 29/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 2.8442 - val_accuracy: 0.6288\n",
            "Epoch 30/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 3.0271 - val_accuracy: 0.6153\n",
            "Epoch 31/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 2.9805 - val_accuracy: 0.6184\n",
            "Epoch 32/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 3.0425 - val_accuracy: 0.6191\n",
            "Epoch 33/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 3.1722 - val_accuracy: 0.6125\n",
            "Epoch 34/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 3.2734 - val_accuracy: 0.6175\n",
            "Epoch 35/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.3439e-04 - accuracy: 0.9999 - val_loss: 3.2903 - val_accuracy: 0.6212\n",
            "Epoch 36/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.4698e-04 - accuracy: 0.9998 - val_loss: 3.3270 - val_accuracy: 0.6247\n",
            "Epoch 37/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.6237e-04 - accuracy: 0.9999 - val_loss: 3.3653 - val_accuracy: 0.6144\n",
            "Epoch 38/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 4.0355e-04 - accuracy: 0.9999 - val_loss: 3.4326 - val_accuracy: 0.6241\n",
            "Epoch 39/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 6.9247e-04 - accuracy: 0.9999 - val_loss: 3.5416 - val_accuracy: 0.6137\n",
            "Epoch 40/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 3.5105 - val_accuracy: 0.6184\n",
            "Epoch 41/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.6346e-04 - accuracy: 0.9999 - val_loss: 3.5084 - val_accuracy: 0.6209\n",
            "Epoch 42/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 3.5539 - val_accuracy: 0.6131\n",
            "Epoch 43/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.3462e-04 - accuracy: 0.9999 - val_loss: 3.5885 - val_accuracy: 0.6087\n",
            "Epoch 44/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 3.5247 - val_accuracy: 0.6175\n",
            "Epoch 45/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.5496e-04 - accuracy: 0.9999 - val_loss: 3.6121 - val_accuracy: 0.6053\n",
            "Epoch 46/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.5496e-04 - accuracy: 0.9998 - val_loss: 3.5157 - val_accuracy: 0.6191\n",
            "Epoch 47/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.2355e-04 - accuracy: 0.9998 - val_loss: 3.5590 - val_accuracy: 0.6100\n",
            "Epoch 48/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.4926e-04 - accuracy: 0.9998 - val_loss: 3.5362 - val_accuracy: 0.6169\n",
            "Epoch 49/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.5472e-04 - accuracy: 0.9998 - val_loss: 3.5242 - val_accuracy: 0.6197\n",
            "Epoch 50/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.5865e-04 - accuracy: 0.9998 - val_loss: 3.5290 - val_accuracy: 0.6209\n",
            "Epoch 51/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.3501e-04 - accuracy: 0.9999 - val_loss: 3.5394 - val_accuracy: 0.6269\n",
            "Epoch 52/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.8620e-04 - accuracy: 0.9999 - val_loss: 3.6343 - val_accuracy: 0.6078\n",
            "Epoch 53/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.9404e-04 - accuracy: 0.9999 - val_loss: 3.5618 - val_accuracy: 0.6191\n",
            "Epoch 54/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.4533e-04 - accuracy: 0.9999 - val_loss: 3.5856 - val_accuracy: 0.6141\n",
            "Epoch 55/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.2393e-04 - accuracy: 0.9999 - val_loss: 3.5841 - val_accuracy: 0.6166\n",
            "Epoch 56/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.8148e-04 - accuracy: 0.9998 - val_loss: 3.5583 - val_accuracy: 0.6219\n",
            "Epoch 57/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.6107e-04 - accuracy: 0.9998 - val_loss: 3.5363 - val_accuracy: 0.6234\n",
            "Epoch 58/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.3460e-04 - accuracy: 0.9999 - val_loss: 3.6505 - val_accuracy: 0.6047\n",
            "Epoch 59/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.6173e-04 - accuracy: 0.9999 - val_loss: 3.5584 - val_accuracy: 0.6225\n",
            "Epoch 60/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.3987e-04 - accuracy: 0.9999 - val_loss: 3.6446 - val_accuracy: 0.6081\n",
            "Epoch 61/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.3289e-04 - accuracy: 0.9998 - val_loss: 3.5737 - val_accuracy: 0.6203\n",
            "Epoch 62/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.3872e-04 - accuracy: 0.9999 - val_loss: 3.5555 - val_accuracy: 0.6266\n",
            "Epoch 63/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.3549e-04 - accuracy: 0.9999 - val_loss: 3.5919 - val_accuracy: 0.6172\n",
            "Epoch 64/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.1564e-04 - accuracy: 0.9998 - val_loss: 3.5599 - val_accuracy: 0.6259\n",
            "Epoch 65/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.4777e-04 - accuracy: 0.9999 - val_loss: 3.5834 - val_accuracy: 0.6219\n",
            "Epoch 66/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.4170e-04 - accuracy: 0.9999 - val_loss: 3.5832 - val_accuracy: 0.6225\n",
            "Epoch 67/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.2203e-04 - accuracy: 0.9998 - val_loss: 3.5768 - val_accuracy: 0.6219\n",
            "Epoch 68/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 6.8151e-04 - accuracy: 0.9999 - val_loss: 3.5781 - val_accuracy: 0.6244\n",
            "Epoch 69/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.7354e-04 - accuracy: 0.9998 - val_loss: 3.5610 - val_accuracy: 0.6241\n",
            "Epoch 70/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.8298e-04 - accuracy: 0.9998 - val_loss: 3.5727 - val_accuracy: 0.6222\n",
            "Epoch 71/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.3271e-04 - accuracy: 0.9998 - val_loss: 3.5710 - val_accuracy: 0.6228\n",
            "Epoch 72/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.3404e-04 - accuracy: 0.9999 - val_loss: 3.6258 - val_accuracy: 0.6087\n",
            "Epoch 73/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 3.2127e-04 - accuracy: 0.9998 - val_loss: 3.6146 - val_accuracy: 0.6219\n",
            "Epoch 74/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.1641e-04 - accuracy: 0.9998 - val_loss: 3.5915 - val_accuracy: 0.6256\n",
            "Epoch 75/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.3575e-04 - accuracy: 0.9998 - val_loss: 3.5771 - val_accuracy: 0.6225\n",
            "Epoch 76/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.0050e-04 - accuracy: 0.9999 - val_loss: 3.6327 - val_accuracy: 0.6134\n",
            "Epoch 77/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.6843e-04 - accuracy: 0.9998 - val_loss: 3.5922 - val_accuracy: 0.6247\n",
            "Epoch 78/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.3363e-04 - accuracy: 0.9999 - val_loss: 3.5945 - val_accuracy: 0.6247\n",
            "Epoch 79/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.1770e-04 - accuracy: 0.9998 - val_loss: 3.5720 - val_accuracy: 0.6256\n",
            "Epoch 80/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.5584e-04 - accuracy: 0.9998 - val_loss: 3.5722 - val_accuracy: 0.6209\n",
            "Epoch 81/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.9130e-04 - accuracy: 0.9998 - val_loss: 3.5769 - val_accuracy: 0.6184\n",
            "Epoch 82/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.9093e-04 - accuracy: 0.9998 - val_loss: 3.5633 - val_accuracy: 0.6203\n",
            "Epoch 83/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.8292e-04 - accuracy: 0.9998 - val_loss: 3.5735 - val_accuracy: 0.6191\n",
            "Epoch 84/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.4814e-04 - accuracy: 0.9999 - val_loss: 3.6415 - val_accuracy: 0.6069\n",
            "Epoch 85/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 9.6890e-04 - accuracy: 0.9998 - val_loss: 3.5492 - val_accuracy: 0.6203\n",
            "Epoch 86/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.7458e-04 - accuracy: 0.9998 - val_loss: 3.5233 - val_accuracy: 0.6212\n",
            "Epoch 87/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.5720e-04 - accuracy: 0.9998 - val_loss: 3.5270 - val_accuracy: 0.6269\n",
            "Epoch 88/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.5860e-04 - accuracy: 0.9998 - val_loss: 3.5214 - val_accuracy: 0.6212\n",
            "Epoch 89/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.4965e-04 - accuracy: 0.9999 - val_loss: 3.5229 - val_accuracy: 0.6322\n",
            "Epoch 90/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.3254e-04 - accuracy: 0.9998 - val_loss: 3.5334 - val_accuracy: 0.6225\n",
            "Epoch 91/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.0976e-04 - accuracy: 0.9998 - val_loss: 3.5207 - val_accuracy: 0.6219\n",
            "Epoch 92/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.4065e-04 - accuracy: 0.9998 - val_loss: 3.5228 - val_accuracy: 0.6222\n",
            "Epoch 93/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.3299e-04 - accuracy: 0.9999 - val_loss: 3.5901 - val_accuracy: 0.6091\n",
            "Epoch 94/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.8597e-04 - accuracy: 0.9999 - val_loss: 3.5190 - val_accuracy: 0.6269\n",
            "Epoch 95/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.4407e-04 - accuracy: 0.9999 - val_loss: 3.5289 - val_accuracy: 0.6266\n",
            "Epoch 96/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 8.3359e-04 - accuracy: 0.9998 - val_loss: 3.5238 - val_accuracy: 0.6222\n",
            "Epoch 97/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 6.9367e-04 - accuracy: 0.9999 - val_loss: 3.5404 - val_accuracy: 0.6297\n",
            "Epoch 98/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 6.4621e-04 - accuracy: 0.9999 - val_loss: 3.6330 - val_accuracy: 0.6112\n",
            "Epoch 99/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 4.2378e-04 - accuracy: 0.9999 - val_loss: 3.5646 - val_accuracy: 0.6209\n",
            "Epoch 100/100\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 7.6790e-04 - accuracy: 0.9999 - val_loss: 3.5639 - val_accuracy: 0.6181\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.62      0.62      1604\n",
            "           1       0.62      0.62      0.62      1596\n",
            "\n",
            "    accuracy                           0.62      3200\n",
            "   macro avg       0.62      0.62      0.62      3200\n",
            "weighted avg       0.62      0.62      0.62      3200\n",
            "\n",
            "Accuracy : 0.62125\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ISc4sJrx_rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ta5tP7Rv8PpS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_train_ds = tf.convert_to_tensor(X_train)\n",
        "X_val_ds = tf.convert_to_tensor(X_val)\n",
        "X_test_ds = tf.convert_to_tensor(X_test)\n",
        "y_train_ds = tf.convert_to_tensor(y_train)\n",
        "y_val_ds = tf.convert_to_tensor(y_val)\n",
        "y_test_ds= tf.convert_to_tensor(y_test)"
      ],
      "metadata": {
        "id": "b5quvm2ix_sk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(X_train_ds)"
      ],
      "metadata": {
        "id": "UR2-rhTKx_tc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vseR_058Cgeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM model**"
      ],
      "metadata": {
        "id": "fFftIdzwCgq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zqFv6KkMCg2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_model(experiment_name: str, run_name: str):\n",
        "    X = data['text'].values\n",
        "    y = data['target'].values\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "    mlflow.end_run()\n",
        "        # Produces train and val splits.\n",
        "    mlflow.set_experiment(experiment_name)\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "      mlflow.sklearn.autolog()\n",
        "      t = Tokenizer()\n",
        "      t.fit_on_texts(X_train)\n",
        "\n",
        "      encoded_train = t.texts_to_sequences(X_train)\n",
        "      encoded_test = t.texts_to_sequences(X_test)\n",
        "      print(encoded_train[0:2])\n",
        "\n",
        "      max_length = 8\n",
        "      padded_train = pad_sequences(encoded_train, maxlen=max_length, padding='post')\n",
        "      padded_test = pad_sequences(encoded_test, maxlen=max_length, padding='post')\n",
        "      #print(padded_train)\n",
        "\n",
        "      vocab_size = len(t.word_index) + 1\n",
        "\n",
        "      # define the model\n",
        "      model = Sequential()\n",
        "      #model.add(Embedding(vocab_size, 128, input_length=max_length))\n",
        "      tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True)\n",
        "      #tf.keras.layers.Embedding(800, 64, mask_zero=True)\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=False)),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "      model.add(Dense(1, activation='relu'))\n",
        "\n",
        "      # compile the model\n",
        "      model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      # summarize the model\n",
        "      #print(model.summary())\n",
        "\n",
        "      early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "      # fit the model\n",
        "      model.fit(x=padded_train,\n",
        "         y=y_train,\n",
        "         epochs=100,\n",
        "         validation_data=(padded_test, y_test), verbose=1,\n",
        "         callbacks=[early_stop]\n",
        "         )\n",
        "\n",
        "      preds = (model.predict(padded_test) > 0.5).astype(\"int32\")\n",
        "      c_report(y_test, preds)\n",
        "      plot_confusion_matrix(y_test, preds)\n",
        "      accuracy=accuracy_score(y_test, preds, normalize=True)\n",
        "      f1_Score= f1_score(y_test, preds)\n",
        "      mlflow.log_metric(\"accuracy\", accuracy)\n",
        "      mlflow.log_metric(\"f1_Score\", f1_Score)"
      ],
      "metadata": {
        "id": "K2mR7Bj60igd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "POFesSJZ0ijM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model('lstm model','lstm first model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g_gYe9Y-0imJ",
        "outputId": "e1b2e953-b3c5-4683-9863-0cd05956856a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[226, 72, 32, 5, 1660, 49, 260, 72, 370, 6821, 731, 90, 71, 563, 1845, 18, 466, 5, 4438], [6822, 189, 120, 339, 4, 859, 12, 860]]\n",
            "Epoch 1/100\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 7.8835 - accuracy: 0.4840 - val_loss: 7.9744 - val_accuracy: 0.4778\n",
            "Epoch 2/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 7.8857 - accuracy: 0.4839 - val_loss: 7.9744 - val_accuracy: 0.4778\n",
            "Epoch 3/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 7.8857 - accuracy: 0.4839 - val_loss: 7.9744 - val_accuracy: 0.4778\n",
            "Epoch 4/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 7.8857 - accuracy: 0.4839 - val_loss: 7.9744 - val_accuracy: 0.4778\n",
            "Epoch 5/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 7.8857 - accuracy: 0.4839 - val_loss: 7.9744 - val_accuracy: 0.4778\n",
            "Epoch 6/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 7.8857 - accuracy: 0.4839 - val_loss: 7.9744 - val_accuracy: 0.4778\n",
            "Epoch 7/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 7.8857 - accuracy: 0.4839 - val_loss: 7.9744 - val_accuracy: 0.4778\n",
            "Epoch 8/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 7.8857 - accuracy: 0.4839 - val_loss: 7.9744 - val_accuracy: 0.4778\n",
            "Epoch 9/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 7.8857 - accuracy: 0.4839 - val_loss: 7.9744 - val_accuracy: 0.4778\n",
            "Epoch 10/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 7.8857 - accuracy: 0.4839 - val_loss: 7.9744 - val_accuracy: 0.4778\n",
            "Epoch 11/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 7.8857 - accuracy: 0.4839 - val_loss: 7.9744 - val_accuracy: 0.4778\n",
            "Epoch 11: early stopping\n",
            "100/100 [==============================] - 0s 885us/step\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.09      0.14      1604\n",
            "           1       0.49      0.87      0.62      1596\n",
            "\n",
            "    accuracy                           0.48      3200\n",
            "   macro avg       0.45      0.48      0.38      3200\n",
            "weighted avg       0.45      0.48      0.38      3200\n",
            "\n",
            "Accuracy : 0.4778125\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6iMZS7V00ipq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ct99Zo3extDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced model BERT"
      ],
      "metadata": {
        "id": "QqctoLcCIIg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ioRNtpjmIIrp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "54vvl7-dWKd-"
      },
      "outputs": [],
      "source": [
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JHRu3rMXsjE",
        "outputId": "2313efbb-0431-42d4-e243-80cf6841e296"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
              "array([[-0.84351677, -0.51327246, -0.888457  , ..., -0.7474884 ,\n",
              "        -0.75314724,  0.91964483],\n",
              "       [-0.84345585, -0.3269479 , -0.01910536, ...,  0.30374014,\n",
              "        -0.59399104,  0.86496323]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "def get_sentence_embeding(sentences):\n",
        "    preprocessed_text = bert_preprocess(sentences)\n",
        "    return bert_encoder(preprocessed_text)['pooled_output']\n",
        "\n",
        "get_sentence_embeding([\n",
        "    \"500$ discount. hurry up\",\n",
        "    \"lebron james is the goat\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "gXmviG2EYCU6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Sthxh_sBYR13"
      },
      "outputs": [],
      "source": [
        "# Bert layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "# Neural network layers\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "\n",
        "# Use inputs and outputs to construct a final model\n",
        "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7nUcU3E0Dg1O"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t5wwjGNd6gG3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_analyser(experiment_name,run_name,activation,epochs):\n",
        "\n",
        " mlflow.end_run()\n",
        " mlflow.set_experiment(experiment_name)\n",
        " with mlflow.start_run(run_name=run_name):\n",
        "    mlflow.sklearn.autolog()\n",
        "    bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "    bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
        "\n",
        "    # Bert layers\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    preprocessed_text = bert_preprocess(text_input)\n",
        "    outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "    # Neural network layers\n",
        "    l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "    l = tf.keras.layers.Dense(1, activation= activation, name=\"output\")(l)\n",
        "\n",
        "    # Use inputs and outputs to construct a final model\n",
        "    model = tf.keras.Model(inputs=[text_input], outputs = [l])\n",
        "\n",
        "    METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS)\n",
        "    #mlflow.log_metric(\"METRICS\", tf.keras.metrics.BinaryAccuracy(name='accuracy'))\n",
        "    model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "    model.evaluate(X_train, y_train)\n",
        "\n",
        "    #model.evaluate(X_train, y_train)\n",
        "\n",
        "    y_predicted = model.predict(X_test)\n",
        "\n",
        "    y_predicted = y_predicted.flatten()\n",
        "\n",
        "\n",
        "    y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
        "\n",
        "    accuracy= accuracy_score(y_test,y_predicted)\n",
        "    F1_score= f1_score(y_test,y_predicted)\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"F1_score\", F1_score)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nMWpsVoX6cfZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= bert_analyser('bert_sig','bert_sig','sigmoid',10)"
      ],
      "metadata": {
        "id": "xYMLs4_n6cpO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee4cc0c-6985-4daf-db00-7aee7fba7f9d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "400/400 [==============================] - 611s 2s/step - loss: 0.6655 - accuracy: 0.5936 - precision: 0.5918 - recall: 0.5958\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 611s 2s/step - loss: 0.6188 - accuracy: 0.6591 - precision: 0.6539 - recall: 0.6717\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 604s 2s/step - loss: 0.5921 - accuracy: 0.6820 - precision: 0.6766 - recall: 0.6936\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 589s 1s/step - loss: 0.5825 - accuracy: 0.6880 - precision: 0.6804 - recall: 0.7057\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 593s 1s/step - loss: 0.5721 - accuracy: 0.7066 - precision: 0.7002 - recall: 0.7195\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 579s 1s/step - loss: 0.5642 - accuracy: 0.7080 - precision: 0.7030 - recall: 0.7174\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 578s 1s/step - loss: 0.5611 - accuracy: 0.7078 - precision: 0.7024 - recall: 0.7182\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 576s 1s/step - loss: 0.5549 - accuracy: 0.7173 - precision: 0.7113 - recall: 0.7286\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 575s 1s/step - loss: 0.5498 - accuracy: 0.7195 - precision: 0.7133 - recall: 0.7314\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 572s 1s/step - loss: 0.5510 - accuracy: 0.7184 - precision: 0.7146 - recall: 0.7243\n",
            "400/400 [==============================] - 568s 1s/step - loss: 0.5267 - accuracy: 0.7398 - precision: 0.7201 - recall: 0.7820\n",
            "50/50 [==============================] - 73s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJSKZ5eHYR31"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "7dJOjHqe2ZkW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MaknFnyYR6Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "E96rFga-YR9o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "EQodun_fZJQf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "kGvhLe_B11WN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "loFBtbDXfP0K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uTgp0mvy4MMS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "AFPKksHF4itt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "r_c5hw4Y4rxf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5CTBgp9b4rz7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "sOtFYZ4L4r3R"
      },
      "outputs": [],
      "source": [
        "def bert_analyser(experiment_name,run_name,activation,epoch):\n",
        "\n",
        " mlflow.end_run()\n",
        " mlflow.set_experiment(experiment_name)\n",
        " with mlflow.start_run(run_name=run_name):\n",
        "    mlflow.sklearn.autolog()\n",
        "    bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "    bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
        "\n",
        "    # Bert layers\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    preprocessed_text = bert_preprocess(text_input)\n",
        "    outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "    # Neural network layers\n",
        "    l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "    l = tf.keras.layers.Dense(1, activation= activation, name=\"output\")(l)\n",
        "\n",
        "    # Use inputs and outputs to construct a final model\n",
        "    model = tf.keras.Model(inputs=[text_input], outputs = [l])\n",
        "\n",
        "    METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS)\n",
        "    #mlflow.log_metric(\"METRICS\", tf.keras.metrics.BinaryAccuracy(name='accuracy'))\n",
        "    model.fit(X_train, y_train, epochs=epoch)\n",
        "\n",
        "    model.evaluate(X_train, y_train)\n",
        "\n",
        "    #model.evaluate(X_train, y_train)\n",
        "\n",
        "    y_predicted = model.predict(X_test)\n",
        "\n",
        "    y_predicted = y_predicted.flatten()\n",
        "\n",
        "\n",
        "    y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
        "\n",
        "    accuracy= accuracy_score(y_test,y_predicted)\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    F1_score= f1_score(y_test,y_predicted)\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"F1_score\", F1_score)\n",
        "    y_predicted\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_predicted)\n",
        "    cm\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jF37mBNFCfY",
        "outputId": "77dd67a5-cf9a-4f04-936c-9a5d01551af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "400/400 [==============================] - 615s 2s/step - loss: 4.9183 - accuracy: 0.4963 - precision: 0.4891 - recall: 0.2318\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 615s 2s/step - loss: 4.8938 - accuracy: 0.5198 - precision: 0.5120 - recall: 0.7866\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 587s 1s/step - loss: 7.0202 - accuracy: 0.5057 - precision: 0.5225 - recall: 0.0981\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 583s 1s/step - loss: 7.6896 - accuracy: 0.5015 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 586s 1s/step - loss: 7.6896 - accuracy: 0.5015 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "400/400 [==============================] - 633s 2s/step - loss: 7.6896 - accuracy: 0.5015 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "50/50 [==============================] - 87s 2s/step\n"
          ]
        }
      ],
      "source": [
        "bert_analyser('bert_relu','relu','relu',5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65mP9WobSL1c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnY8Q1jWSL4F",
        "outputId": "01d4f76e-a6ce-4972-8f4b-7cd0936c5787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/10/31 15:22:04 INFO mlflow.tracking.fluent: Experiment with name 'bert_tanh' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "400/400 [==============================] - 619s 2s/step - loss: 0.9789 - accuracy: 0.5393 - precision: 0.5258 - recall: 0.7737\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 579s 1s/step - loss: 0.8785 - accuracy: 0.5925 - precision: 0.5662 - recall: 0.7804\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 575s 1s/step - loss: 0.8394 - accuracy: 0.6114 - precision: 0.5832 - recall: 0.7724\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 578s 1s/step - loss: 0.7742 - accuracy: 0.6077 - precision: 0.5761 - recall: 0.8065\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 576s 1s/step - loss: 3.1130 - accuracy: 0.5793 - precision: 0.5504 - recall: 0.8528\n",
            "400/400 [==============================] - 728s 2s/step - loss: 7.1974 - accuracy: 0.4986 - precision: 0.4986 - recall: 0.9998\n",
            "50/50 [==============================] - 96s 2s/step\n"
          ]
        }
      ],
      "source": [
        "bert_analyser('bert_tanh','tanh','tanh',5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "fn0epgE3SL6t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41MkboXBSL9j",
        "outputId": "95e535e0-44ba-4348-ed17-274f445c386e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/10/31 16:24:47 INFO mlflow.tracking.fluent: Experiment with name 'bert_sigmoid' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "400/400 [==============================] - 763s 2s/step - loss: 0.6643 - accuracy: 0.5918 - precision: 0.5898 - recall: 0.5949\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 653s 2s/step - loss: 0.6171 - accuracy: 0.6634 - precision: 0.6579 - recall: 0.6765\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 573s 1s/step - loss: 0.5937 - accuracy: 0.6854 - precision: 0.6782 - recall: 0.7019\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 578s 1s/step - loss: 0.5798 - accuracy: 0.6995 - precision: 0.6946 - recall: 0.7090\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 570s 1s/step - loss: 0.5701 - accuracy: 0.7048 - precision: 0.6995 - recall: 0.7152\n",
            "400/400 [==============================] - 577s 1s/step - loss: 0.5525 - accuracy: 0.7200 - precision: 0.6868 - recall: 0.8058\n",
            "50/50 [==============================] - 76s 1s/step\n"
          ]
        }
      ],
      "source": [
        "bert_analyser('bert_sigmoid','sigmoid','sigmoid',5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yak7BfpzSMA8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_analyser(experiment_name,run_name,activation,epochs):\n",
        "\n",
        " mlflow.end_run()\n",
        " mlflow.set_experiment(experiment_name)\n",
        " with mlflow.start_run(run_name=run_name):\n",
        "    mlflow.sklearn.autolog()\n",
        "    bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "    bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
        "\n",
        "    # Bert layers\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    preprocessed_text = bert_preprocess(text_input)\n",
        "    outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "    # Neural network layers\n",
        "    l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "    l = tf.keras.layers.Dense(1, activation= activation, name=\"output\")(l)\n",
        "\n",
        "    # Use inputs and outputs to construct a final model\n",
        "    model = tf.keras.Model(inputs=[text_input], outputs = [l])\n",
        "\n",
        "    METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS)\n",
        "    #mlflow.log_metric(\"METRICS\", tf.keras.metrics.BinaryAccuracy(name='accuracy'))\n",
        "    model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "    model.evaluate(X_train, y_train)\n",
        "\n",
        "    #model.evaluate(X_train, y_train)\n",
        "\n",
        "    y_predicted = model.predict(X_test)\n",
        "\n",
        "    y_predicted = y_predicted.flatten()\n",
        "\n",
        "\n",
        "    y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
        "\n",
        "    accuracy= accuracy_score(y_test,y_predicted)\n",
        "    f1_score= f1_score(y_test,y_predicted)\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"F1_score\", F1_score)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j2RaAStd08EB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XKg1W5T508KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "JP7O-MXpFiqg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "yYzhWVuhFt_a"
      },
      "outputs": [],
      "source": [
        "def serve_model_experiment(NGROK_AUTH_TOKEN):\n",
        "  # Terminate open tunnels if exist\n",
        "  #ngrok.kill(NGROK_AUTH_TOKEN)\n",
        "\n",
        "  # Setting the authtoken (optional)\n",
        "  # Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "  NGROK_AUTH_TOKEN = NGROK_AUTH_TOKEN\n",
        "  ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "  # Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "  ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "  print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)\n",
        "\n",
        "\n",
        "token=config_ngrok['token']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR4_YpPyCxEW",
        "outputId": "f6ffa4ad-3bf6-4e5b-d879-d08ec6af6335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-10-31T17:44:35+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: https://450a-34-41-232-114.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "serve_model_experiment(token)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall black\n",
        "!pip uninstall click\n",
        "!pip install black\n",
        "!pip install click"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "f8OOJZkH0pOm",
        "outputId": "31946ac1-e0da-4253-fc0d-327b4aa9d090"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping black as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: click 7.1.2\n",
            "Uninstalling click-7.1.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/click-7.1.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/click/*\n",
            "Proceed (Y/n)? \u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting black\n",
            "  Downloading black-23.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click>=8.0.0 (from black)\n",
            "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.4.3 (from black)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black) (23.2)\n",
            "Collecting pathspec>=0.9.0 (from black)\n",
            "  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black) (3.11.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black) (4.5.0)\n",
            "Installing collected packages: pathspec, mypy-extensions, click, black\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "uvicorn 0.13.1 requires click==7.*, but you have click 8.1.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed black-23.10.1 click-8.1.7 mypy-extensions-1.0.0 pathspec-0.11.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "click"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (8.1.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQU1UCWQ0pR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SjSVRjsFuCJ",
        "outputId": "c38e39bd-6bc0-445f-f90c-b7284aa1c43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-10-31 17:44:41 +0000] [148790] [INFO] Starting gunicorn 21.2.0\n",
            "[2023-10-31 17:44:41 +0000] [148790] [INFO] Listening at: http://127.0.0.1:5000 (148790)\n",
            "[2023-10-31 17:44:41 +0000] [148790] [INFO] Using worker: sync\n",
            "[2023-10-31 17:44:41 +0000] [148791] [INFO] Booting worker with pid: 148791\n",
            "[2023-10-31 17:44:41 +0000] [148792] [INFO] Booting worker with pid: 148792\n",
            "[2023-10-31 17:44:41 +0000] [148797] [INFO] Booting worker with pid: 148797\n",
            "[2023-10-31 17:44:41 +0000] [148798] [INFO] Booting worker with pid: 148798\n",
            "\n",
            "Aborted!\n",
            "[2023-10-31 18:24:50 +0000] [148790] [INFO] Handling signal: int\n",
            "[2023-10-31 18:24:50 +0000] [148792] [INFO] Worker exiting (pid: 148792)\n",
            "[2023-10-31 18:24:50 +0000] [148791] [INFO] Worker exiting (pid: 148791)\n",
            "[2023-10-31 18:24:50 +0000] [148797] [INFO] Worker exiting (pid: 148797)\n",
            "[2023-10-31 18:24:50 +0000] [148798] [INFO] Worker exiting (pid: 148798)\n",
            "[2023-10-31 18:24:51 +0000] [148790] [INFO] Shutting down: Master\n"
          ]
        }
      ],
      "source": [
        "!mlflow ui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu7cnijXFuFi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdz3jr9YpngJ"
      },
      "outputs": [],
      "source": [
        "#import pickle\n",
        "#Pkl_Filename = \"src/model_bert.pkl\"\n",
        "\n",
        "#with open(Pkl_Filename, 'wb') as file:\n",
        "#   pickle.dump(model, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Om_IRlipniq"
      },
      "outputs": [],
      "source": [
        "model.save('bad_buzz_detection/src/model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive_path = \"/content/gdrive\"\n",
        "drive.mount(drive_path,force_remount=True)\n",
        "\n",
        "# Load the general config\n",
        "config_path = os.path.join(drive_path, \"MyDrive\", \"general_config.yml\")\n",
        "with open(config_path, 'r') as yml:\n",
        "  config = yaml.safe_load(yml)\n",
        "\n",
        "config_github = config[\"github\"]\n",
        "config_ngrok = config[\"ngrok\"]\n",
        "\n",
        "# Set git configs\n",
        "!git config --global user.email {config_github[\"email\"]}\n",
        "!git config --global user.name {config_github[\"username\"]}\n",
        "repository_name = \"bad_buzz_detection\"\n",
        "git_repository = f\"https://github.com/dibalaba/\" + repository_name + \".git\"\n",
        "repository_path = repository_name\n",
        "#\"/content/\" + repository_name\n",
        "#!git clone {git_repository}\n",
        "\n",
        "# Change the current directory to the cloned directory\n",
        "#%cd {repository_name}\n",
        "\n",
        "# Checkout branch\n",
        "branch_name = \"main\"\n",
        "#!git checkout {branch_name}\n",
        "!git push"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCgZBJFXICtT",
        "outputId": "f4993a68-3d9a-48fd-986c-46e9ae5602be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "azt4k9BVKfb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/bad_buzz_detection/bad_buzz_detection/src/model.pkl.zip  /content/bad_buzz_detection/bad_buzz_detection/src/model.pkl"
      ],
      "metadata": {
        "id": "b_KOai0CKtAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e948e9-5b93-4491-ba2f-8604b1c5526a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/bad_buzz_detection/bad_buzz_detection/src/model.pkl/ (stored 0%)\n",
            "  adding: content/bad_buzz_detection/bad_buzz_detection/src/model.pkl/saved_model.pb (deflated 92%)\n",
            "  adding: content/bad_buzz_detection/bad_buzz_detection/src/model.pkl/fingerprint.pb (stored 0%)\n",
            "  adding: content/bad_buzz_detection/bad_buzz_detection/src/model.pkl/assets/ (stored 0%)\n",
            "  adding: content/bad_buzz_detection/bad_buzz_detection/src/model.pkl/assets/vocab.txt (deflated 53%)\n",
            "  adding: content/bad_buzz_detection/bad_buzz_detection/src/model.pkl/keras_metadata.pb (deflated 84%)\n",
            "  adding: content/bad_buzz_detection/bad_buzz_detection/src/model.pkl/variables/ (stored 0%)\n",
            "  adding: content/bad_buzz_detection/bad_buzz_detection/src/model.pkl/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/bad_buzz_detection/bad_buzz_detection/src/model.pkl/variables/variables.index (deflated 79%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/bad_buzz_detection/bad_buzz_detection/src/model.pkl.zip')"
      ],
      "metadata": {
        "id": "-pdUUmTeKfhn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c73e8ea9-b996-4474-b747-9d20cc4adfa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5be6ec4b-b09d-4fd8-9d88-5ddb811c9d30\", \"model.pkl.zip\", 408714289)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modele=tf.saved_model.save(model, '/bad_buzz_detection/src/model.pkl/saved_model.pb')"
      ],
      "metadata": {
        "id": "xVfGXLRuojYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YZthCR53ojbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZSh-Ihcxojjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_tb1oxZeICws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNWBdi2lpnlD"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "#from string import string\n",
        "class Tweet(BaseModel):\n",
        "    text: str\n",
        "\n",
        "class Item(BaseModel):\n",
        "    sentiment: str\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hYhYFzHg2yul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RaaTvVQi2zAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54zbtLxmpnp5"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI,Response\n",
        "import pickle\n",
        "import json\n",
        "from fastapi import FastAPI\n",
        "from fastapi.encoders import jsonable_encoder\n",
        "from fastapi.responses import JSONResponse\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global model\n",
        "    #model = pickle.load(open(\"/content/bad_buzz_detection/model_bert.pkl\", \"rb\"))\n",
        "    model = tf.keras.models.load_model('/content/bad_buzz_detection/model.pkl')\n",
        "\n",
        "@app.get('/')\n",
        "def index():\n",
        "    return {'message': 'This is the homepage of the API '}\n",
        "\n",
        "\n",
        "@app.post('/predict',response_model=Item)\n",
        "def analyse_sentiment(data: Tweet):\n",
        "    received = data.dict()\n",
        "    text = received['text']\n",
        "\n",
        "    pred_name = model.predict([text])\n",
        "\n",
        "\n",
        "    result = 'You\\'re sentiment is positive thank you' if pred_name > 0.5 else 'Thank you anyway'\n",
        "\n",
        "    return {\"sentiment\" : str(result)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFuBKiE5cdXO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgmOHsd1fHZv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gE3IpXypnu6"
      },
      "outputs": [],
      "source": [
        "from colabcode import ColabCode\n",
        "server = ColabCode(port=10000, code=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJJmtDeHpnyT",
        "outputId": "ed448d8d-a93e-43ea-b84d-ebefe817f670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://f54f-35-239-83-44.ngrok-free.app\" -> \"http://localhost:10000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [3813]\n",
            "INFO:uvicorn.error:Started server process [3813]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:uvicorn.error:Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:uvicorn.error:Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:10000 (Press CTRL+C to quit)\n",
            "INFO:uvicorn.error:Uvicorn running on http://127.0.0.1:10000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "INFO:     88.180.43.200:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 172ms/step\n",
            "INFO:     88.180.43.200:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 158ms/step\n",
            "INFO:     88.180.43.200:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 155ms/step\n",
            "INFO:     88.180.43.200:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "INFO:     88.180.43.200:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 165ms/step\n",
            "INFO:     88.180.43.200:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 158ms/step\n",
            "INFO:     88.180.43.200:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 153ms/step\n",
            "INFO:     88.180.43.200:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 164ms/step\n",
            "INFO:     88.180.43.200:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "INFO:     88.180.43.200:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2a01:e0a:d0a:f200:7847:f0fc:2295:feed:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     2a01:e0a:d0a:f200:7847:f0fc:2295:feed:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     2a01:e0a:d0a:f200:7847:f0fc:2295:feed:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     2a01:e0a:d0a:f200:7847:f0fc:2295:feed:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n",
            "1/1 [==============================] - 0s 168ms/step\n",
            "INFO:     2a01:e0a:d0a:f200:7847:f0fc:2295:feed:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "INFO:     2a01:e0a:d0a:f200:7847:f0fc:2295:feed:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 158ms/step\n",
            "INFO:     2a01:e0a:d0a:f200:7847:f0fc:2295:feed:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 163ms/step\n",
            "INFO:     2a01:e0a:d0a:f200:7847:f0fc:2295:feed:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 159ms/step\n",
            "INFO:     2a01:e0a:d0a:f200:7847:f0fc:2295:feed:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 160ms/step\n",
            "INFO:     2a01:e0a:d0a:f200:7847:f0fc:2295:feed:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "INFO:     2a01:e0a:d0a:f200:7847:f0fc:2295:feed:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "1/1 [==============================] - 0s 167ms/step\n",
            "INFO:     2a01:e0a:d0a:f200:7847:f0fc:2295:feed:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:uvicorn.error:Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:uvicorn.error:Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:uvicorn.error:Application shutdown complete.\n",
            "INFO:     Finished server process [3813]\n",
            "INFO:uvicorn.error:Finished server process [3813]\n"
          ]
        }
      ],
      "source": [
        "server.run_app(app=app)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oIlm97QZz9rT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}